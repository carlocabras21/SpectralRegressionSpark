0 tab: locale
1 tab: remoto

---------------------------------
// crea il cluster ed il bucket S3
terraform apply --auto-approve

// copia il file python dentro il cluster
scp -i prima.pem SpectralRegressionSpark.py hadoop@<public_dns>:~/


// connettiti al cluster
ssh -i prima.pem hadoop@PUBLIC_DNS

	// lancia il programma se file inviato tramite scp
	spark-submit --deploy-mode cluster SpectralRegressionSpark.py

	// lancia il programma se file presente in s3
	spark-submit --deploy-mode cluster s3://spectral-regression-spark-bucket/SpectralRegressionSpark.py

	// per leggere il stdout dell'applicazione
	// <log-bucket>/<id-cluster>/containers/<id-applicazione>/ <prima cartella container> / stdout.gz 
	// oppure per leggere tutto il log (tra cui l'output)
	yarn logs --applicationId <your applicationId> > log.txt

// copiare in locale il file di log
scp -i prima.pem hadoop@<public_dns>:~/log.txt <local_destination_path>

// distruggi il cluster ed i bucket S3
terraform destroy --auto-approve

// i bucket vanno prima vuotati manualmente



